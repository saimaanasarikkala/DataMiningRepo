{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'prompt_id', 'text', 'generated'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load data\n",
    "train_essays = pd.read_csv('train_essays.csv')\n",
    "\n",
    "# Merge dataset\n",
    "# Assuming `train_essays` contains both train and dev data\n",
    "# If not, load the dev dataset separately and merge\n",
    "# merged_data = pd.concat([train_essays, dev_essays], ignore_index=True)\n",
    "train_essays.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here ID and prompt id are not required, hence drop them from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'generated'], dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Divide into train and dev\n",
    "train_essays = train_essays.drop(['prompt_id','id'],axis=1)\n",
    "\n",
    "train_data, dev_data = train_test_split(train_essays, test_size=0.2, random_state=42)\n",
    "train_data.shape, dev_data.shape\n",
    "\n",
    "train_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1100\n",
       "1       2\n",
       "Name: generated, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['generated'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So Only 2 essays are AI Generated and the remaining are Human Essays, so we need to make the number of AI Generated Essays and Human Essays equal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_data = pd.read_csv(\"train_v2_drcat_02.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_data = new_data[new_data['label'] == 1].sample(n=600, random_state=42)[['text', 'label']]\n",
    "ai_generated_data = pd.read_csv('ai_generated_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'generated'], dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_generated_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train_data, ai_generated_data], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1702, 2)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1100\n",
       "1     602\n",
       "Name: generated, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['generated'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Create a list of all words in the dataset\n",
    "all_words = ' '.join(df['text']).lower().split()\n",
    "\n",
    "# Count word occurrences\n",
    "word_counts = Counter(all_words)\n",
    "\n",
    "# Build vocabulary\n",
    "vocab = [word for word, count in word_counts.items() if count >= 5]\n",
    "vocab_reverse_index = {word: idx for idx, word in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate P[word]\n",
    "num_documents = len(df)\n",
    "word_probabilities = {word: count / num_documents for word, count in word_counts.items()}\n",
    "\n",
    "# Assuming `generated` column is the target\n",
    "# Separate data into human and LLM essays\n",
    "human_data = df[df['generated'] == 0]\n",
    "llm_data = df[df['generated'] == 1]\n",
    "\n",
    "# Calculate P[word | LLM]\n",
    "llm_word_probabilities = {word: df['text'].apply(lambda essay: word in essay.lower()).mean() for word in vocab}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
